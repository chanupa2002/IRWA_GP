export const mockResults = [
  {
    id: "pf-001",
    title: "Large Language Models for Literature Review: A Survey",
    authors: ["A. Kumar", "B. Li"],
    year: 2024,
    venue: "ACM Computing Surveys",
    url: "https://example.org/paper1",
    pdfUrl: "https://example.org/paper1.pdf",
    source: "ACM",
    abstract:
      "We survey recent methods that use LLMs to assist with systematic reviews, including retrieval, screening, and synthesis."
  },
  {
    id: "pf-002",
    title: "Retriever-Augmented Generation for Scientific Question Answering",
    authors: ["J. Silva", "M. Ahmed"],
    year: 2023,
    venue: "NeurIPS",
    url: "https://example.org/paper2",
    pdfUrl: "https://example.org/paper2.pdf",
    source: "NeurIPS",
    abstract:
      "This work explores RAG pipelines over scholarly corpora and benchmarks evidence grounding for research assistance."
  },
  {
    id: "pf-003",
    title: "Rank, Read, Reason: Pipelines for Academic Discovery",
    authors: ["S. Chen", "L. Novak"],
    year: 2022,
    venue: "arXiv",
    url: "https://example.org/paper3",
    pdfUrl: "https://example.org/paper3.pdf",
    source: "arXiv",
    abstract:
      "We present a practical three-stage pipeline to surface high-quality academic sources for exploratory queries."
  },
  {
    id: "pf-004",
    title: "Efficient Screening for Systematic Reviews with Weak Supervision",
    authors: ["P. Wong"],
    year: 2021,
    venue: "Journal of Biomedical Informatics",
    url: "https://example.org/paper4",
    pdfUrl: "https://example.org/paper4.pdf",
    source: "Elsevier",
    abstract:
      "Combines heuristics and label propagation to accelerate inclusion/exclusion decisions for large citation sets."
  },
  {
    id: "pf-005",
    title: "Prompt Engineering Patterns for Scholarly Search",
    authors: ["D. Ramos", "K. Perera"],
    year: 2024,
    venue: "ACL",
    url: "https://example.org/paper5",
    pdfUrl: "https://example.org/paper5.pdf",
    source: "ACL",
    abstract:
      "We catalogue reusable prompt patterns that improve recall and precision when querying research assistants."
  },
  {
    id: "pf-006",
    title: "From Keywords to Claims: Structuring Literature with LLMs",
    authors: ["N. Gupta"],
    year: 2023,
    venue: "EMNLP",
    url: "https://example.org/paper6",
    pdfUrl: "https://example.org/paper6.pdf",
    source: "EMNLP",
    abstract:
      "A framework that extracts claims, evidence and limitations from papers to speed up narrative synthesis."
  },
  {
    id: "pf-007",
    title: "Benchmarking Scientific Paper Recommenders",
    authors: ["R. Diaz", "T. Ivanov"],
    year: 2020,
    venue: "WWW",
    url: "https://example.org/paper7",
    pdfUrl: "https://example.org/paper7.pdf",
    source: "ACM",
    abstract:
      "A thorough evaluation of collaborative and content-based recommenders on citation graphs."
  },
  {
    id: "pf-008",
    title: "Open Access PDF Extraction at Scale",
    authors: ["Y. Zhang"],
    year: 2019,
    venue: "KDD",
    url: "https://example.org/paper8",
    pdfUrl: "https://example.org/paper8.pdf",
    source: "ACM",
    abstract:
      "Introduces a robust pipeline for fetching and parsing PDFs from heterogeneous scholarly sources."
  },
  {
    id: "pf-009",
    title: "Evaluating Hallucinations in Research Assistants",
    authors: ["C. Brown", "M. Jayawardena"],
    year: 2024,
    venue: "Findings of ACL",
    url: "https://example.org/paper9",
    pdfUrl: "https://example.org/paper9.pdf",
    source: "ACL",
    abstract:
      "Proposes groundedness metrics and human evaluation protocols for scientific assistants."
  },
  {
    id: "pf-010",
    title: "Graph-Based Reranking for Scholarly Retrieval",
    authors: ["E. Rossi"],
    year: 2022,
    venue: "SIGIR",
    url: "https://example.org/paper10",
    pdfUrl: "https://example.org/paper10.pdf",
    source: "ACM",
    abstract:
      "Uses citation and co-authorship graphs to rerank search results for higher authority and coverage."
  }
];
